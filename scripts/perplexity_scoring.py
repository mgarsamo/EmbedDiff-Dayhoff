#!/usr/bin/env python3
"""
Perplexity Scoring Script for EmbedDiff Generated Sequences

This script computes perplexity scores for sequences generated by ESM-2 and Dayhoff models
using a pretrained protein language model (ProtT5 by default).
"""

import argparse
import os
import math
import torch
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from transformers import T5Tokenizer, AutoModelForSeq2SeqLM
from Bio import SeqIO
import numpy as np
from tqdm import tqdm


def load_protein_lm(model_name="Rostlab/prot_t5_xl_uniref50"):
    """
    Load the protein language model and tokenizer.
    
    Args:
        model_name (str): HuggingFace model identifier
        
    Returns:
        tuple: (model, tokenizer)
    """
    print(f"ğŸ”„ Loading protein language model: {model_name}")
    
    try:
        tokenizer = T5Tokenizer.from_pretrained(model_name, do_lower_case=False)
        model = AutoModelForSeq2SeqLM.from_pretrained(model_name)
        
        # Set model to evaluation mode
        model.eval()
        
        # Move to GPU if available
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        model = model.to(device)
        
        print(f"âœ… Model loaded successfully on {device}")
        return model, tokenizer, device
        
    except Exception as e:
        print(f"âŒ Error loading model: {e}")
        raise


def compute_perplexity_batch(sequences, model, tokenizer, device, batch_size=16):
    """
    Compute perplexity for a batch of protein sequences using Seq2SeqLM model.
    
    Args:
        sequences (list): List of protein sequences
        model: Loaded Seq2SeqLM protein language model
        tokenizer: Loaded tokenizer
        device: Device to run computation on
        batch_size (int): Batch size for processing
        
    Returns:
        list: List of perplexity scores
    """
    perplexities = []
    
    # Process sequences in batches
    for i in tqdm(range(0, len(sequences), batch_size), desc="Processing batches", unit="batch"):
        batch_seqs = sequences[i:i + batch_size]
        
        try:
            # Prepare batch inputs
            batch_inputs = []
            for seq in batch_seqs:
                # Add spaces between residues for tokenization
                seq_with_spaces = " ".join(list(seq))
                batch_inputs.append(seq_with_spaces)
            
            # Tokenize batch
            inputs = tokenizer(
                batch_inputs, 
                return_tensors="pt", 
                truncation=True, 
                max_length=512,
                padding=True,
                return_attention_mask=True
            )
            input_ids = inputs["input_ids"].to(device)
            attention_mask = inputs["attention_mask"].to(device)
            
            # Single forward pass with labels - HuggingFace handles shifting automatically
            with torch.no_grad():
                outputs = model(
                    input_ids=input_ids,
                    attention_mask=attention_mask,
                    labels=input_ids  # Pass input_ids as labels for next-token prediction
                )
                logits = outputs.logits  # Shape: [batch_size, seq_len, vocab_size]
            
            # Compute per-sequence losses from logits
            batch_perplexities = []
            for seq_idx in range(len(batch_seqs)):
                # Get sequence-specific logits and labels
                seq_logits = logits[seq_idx]  # Shape: [seq_len, vocab_size]
                seq_labels = input_ids[seq_idx]  # Shape: [seq_len]
                seq_mask = attention_mask[seq_idx]  # Shape: [seq_len]
                
                # Shift for next-token prediction (remove last token from logits, first from labels)
                seq_logits = seq_logits[:-1]  # Shape: [seq_len-1, vocab_size]
                seq_labels = seq_labels[1:]   # Shape: [seq_len-1]
                seq_mask = seq_mask[1:]       # Shape: [seq_len-1]
                
                # Apply cross-entropy loss for this sequence
                loss_fct = torch.nn.CrossEntropyLoss(reduction='none')
                token_losses = loss_fct(seq_logits, seq_labels)  # Shape: [seq_len-1]
                
                # Apply attention mask to ignore padding tokens
                token_losses = token_losses * seq_mask.float()
                
                # Average loss over non-padded tokens
                valid_tokens = seq_mask.sum().item()
                if valid_tokens > 0:
                    avg_loss = token_losses.sum() / valid_tokens
                    perplexity = math.exp(avg_loss.item())
                else:
                    perplexity = None
                
                batch_perplexities.append(perplexity)
            
            perplexities.extend(batch_perplexities)
                
        except Exception as e:
            print(f"âš ï¸ Error processing batch {i//batch_size + 1}: {e}")
            # Add None for failed sequences
            perplexities.extend([None] * len(batch_seqs))
    
    return perplexities


def load_fasta_sequences(fasta_path):
    """
    Load sequences from a FASTA file.
    
    Args:
        fasta_path (str): Path to FASTA file
        
    Returns:
        list: List of sequence strings
    """
    sequences = []
    try:
        for record in SeqIO.parse(fasta_path, "fasta"):
            sequences.append(str(record.seq))
        print(f"ğŸ“ Loaded {len(sequences)} sequences from {fasta_path}")
        return sequences
    except Exception as e:
        print(f"âŒ Error loading sequences from {fasta_path}: {e}")
        return []


def compute_all_perplexities(esm2_fasta, dayhoff_fasta, model_name="Rostlab/prot_t5_xl_uniref50", batch_size=16):
    """
    Compute perplexity scores for all sequences in both FASTA files.
    
    Args:
        esm2_fasta (str): Path to ESM-2 generated sequences
        dayhoff_fasta (str): Path to Dayhoff generated sequences
        model_name (str): Protein language model to use
        batch_size (int): Batch size for processing
        
    Returns:
        pd.DataFrame: DataFrame with perplexity results
    """
    # Load model
    model, tokenizer, device = load_protein_lm(model_name)
    
    # Load sequences
    esm2_sequences = load_fasta_sequences(esm2_fasta)
    dayhoff_sequences = load_fasta_sequences(dayhoff_fasta)
    
    if not esm2_sequences and not dayhoff_sequences:
        raise ValueError("No sequences could be loaded from either FASTA file")
    
    results = []
    
    # Process ESM-2 sequences
    if esm2_sequences:
        print(f"ğŸ”¬ Computing perplexity for {len(esm2_sequences)} ESM-2 sequences (batch size: {batch_size})...")
        esm2_perplexities = compute_perplexity_batch(esm2_sequences, model, tokenizer, device, batch_size)
        
        for seq, perp in zip(esm2_sequences, esm2_perplexities):
            if perp is not None:
                results.append({
                    'sequence': seq,
                    'model': 'ESM-2',
                    'perplexity': perp
                })
    
    # Process Dayhoff sequences
    if dayhoff_sequences:
        print(f"ğŸ”¬ Computing perplexity for {len(dayhoff_sequences)} Dayhoff sequences (batch size: {batch_size})...")
        dayhoff_perplexities = compute_perplexity_batch(dayhoff_sequences, model, tokenizer, device, batch_size)
        
        for seq, perp in zip(dayhoff_sequences, dayhoff_perplexities):
            if perp is not None:
                results.append({
                    'sequence': seq,
                    'model': 'Dayhoff',
                    'perplexity': perp
                })
    
    # Create DataFrame
    df = pd.DataFrame(results)
    print(f"âœ… Computed perplexity for {len(df)} sequences total")
    
    return df


def create_publication_plot(df, output_path):
    """
    Create publication-quality plots comparing perplexity distributions.
    
    Args:
        df (pd.DataFrame): DataFrame with perplexity results
        output_path (str): Path to save the plot
    """
    print("ğŸ¨ Creating publication-quality perplexity comparison plots...")
    
    # Create figure with multiple subplots
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    plt.rcParams['font.size'] = 12
    plt.rcParams['axes.linewidth'] = 1.2
    plt.rcParams['xtick.major.width'] = 1.2
    plt.rcParams['ytick.major.width'] = 1.2
    
    # Colors for each model
    colors = ['#FF6B6B', '#4ECDC4']  # Red for ESM-2, Teal for Dayhoff
    model_names = ['ESM-2', 'Dayhoff']
    
    # 1. Boxplot (linear scale)
    ax1 = axes[0, 0]
    bp = ax1.boxplot([df[df['model'] == 'ESM-2']['perplexity'], 
                     df[df['model'] == 'Dayhoff']['perplexity']],
                    labels=model_names,
                    patch_artist=True,
                    boxprops=dict(facecolor='white', alpha=0.8, linewidth=1.2),
                    medianprops=dict(color='black', linewidth=2),
                    whiskerprops=dict(linewidth=1.2),
                    capprops=dict(linewidth=1.2))
    
    # Color the boxes
    for patch, color in zip(bp['boxes'], colors):
        patch.set_facecolor(color)
        patch.set_alpha(0.7)
    
    ax1.set_ylabel('Perplexity Score', fontsize=14, fontweight='bold')
    ax1.set_title('Perplexity Distribution Comparison (Linear Scale)', fontsize=16, fontweight='bold')
    ax1.grid(axis='y', alpha=0.3, linestyle='--', linewidth=0.8)
    ax1.spines['top'].set_visible(False)
    ax1.spines['right'].set_visible(False)
    
    # 2. Boxplot (log scale)
    ax2 = axes[0, 1]
    bp_log = ax2.boxplot([df[df['model'] == 'ESM-2']['perplexity'], 
                         df[df['model'] == 'Dayhoff']['perplexity']],
                        labels=model_names,
                        patch_artist=True,
                        boxprops=dict(facecolor='white', alpha=0.8, linewidth=1.2),
                        medianprops=dict(color='black', linewidth=2),
                        whiskerprops=dict(linewidth=1.2),
                        capprops=dict(linewidth=1.2))
    
    # Color the boxes
    for patch, color in zip(bp_log['boxes'], colors):
        patch.set_facecolor(color)
        patch.set_alpha(0.7)
    
    ax2.set_ylabel('Perplexity Score (log10)', fontsize=14, fontweight='bold')
    ax2.set_title('Perplexity Distribution Comparison (Log Scale)', fontsize=16, fontweight='bold')
    ax2.set_yscale('log')
    ax2.grid(axis='y', alpha=0.3, linestyle='--', linewidth=0.8)
    ax2.spines['top'].set_visible(False)
    ax2.spines['right'].set_visible(False)
    
    # 3. Histogram with KDE (linear scale)
    ax3 = axes[1, 0]
    for i, model in enumerate(model_names):
        model_data = df[df['model'] == model]['perplexity']
        if len(model_data) > 0:
            # Histogram
            ax3.hist(model_data, bins=30, alpha=0.6, color=colors[i], 
                    label=f'{model} (n={len(model_data)})', density=True)
            
            # KDE curve
            try:
                from scipy.stats import gaussian_kde
                kde = gaussian_kde(model_data)
                x_range = np.linspace(model_data.min(), model_data.max(), 100)
                ax3.plot(x_range, kde(x_range), color=colors[i], linewidth=2, 
                        label=f'{model} KDE')
            except ImportError:
                print("âš ï¸ scipy not available, skipping KDE curves")
    
    ax3.set_xlabel('Perplexity Score', fontsize=14, fontweight='bold')
    ax3.set_ylabel('Density', fontsize=14, fontweight='bold')
    ax3.set_title('Perplexity Distribution Histograms + KDE (Linear Scale)', fontsize=16, fontweight='bold')
    ax3.legend()
    ax3.grid(alpha=0.3, linestyle='--', linewidth=0.8)
    ax3.spines['top'].set_visible(False)
    ax3.spines['right'].set_visible(False)
    
    # 4. Histogram with KDE (log scale)
    ax4 = axes[1, 1]
    for i, model in enumerate(model_names):
        model_data = df[df['model'] == model]['perplexity']
        if len(model_data) > 0:
            # Log-transformed data for histogram
            log_data = np.log10(model_data)
            
            # Histogram
            ax4.hist(log_data, bins=30, alpha=0.6, color=colors[i], 
                    label=f'{model} (n={len(model_data)})', density=True)
            
            # KDE curve on log scale
            try:
                from scipy.stats import gaussian_kde
                kde = gaussian_kde(log_data)
                x_range = np.linspace(log_data.min(), log_data.max(), 100)
                ax4.plot(x_range, kde(x_range), color=colors[i], linewidth=2, 
                        label=f'{model} KDE')
            except ImportError:
                print("âš ï¸ scipy not available, skipping KDE curves")
    
    ax4.set_xlabel('log10(Perplexity Score)', fontsize=14, fontweight='bold')
    ax4.set_ylabel('Density', fontsize=14, fontweight='bold')
    ax4.set_title('Perplexity Distribution Histograms + KDE (Log Scale)', fontsize=16, fontweight='bold')
    ax4.legend()
    ax4.grid(alpha=0.3, linestyle='--', linewidth=0.8)
    ax4.spines['top'].set_visible(False)
    ax4.spines['right'].set_visible(False)
    
    # Adjust layout and save
    plt.tight_layout()
    plt.savefig(output_path, dpi=300, bbox_inches='tight', facecolor='white')
    print(f"ğŸ“Š Comprehensive plots saved to: {output_path}")
    plt.close()


def print_summary_stats(df):
    """
    Print summary statistics for perplexity scores.
    
    Args:
        df (pd.DataFrame): DataFrame with perplexity results
    """
    print("\n" + "="*60)
    print("PERPLEXITY SCORING SUMMARY STATISTICS")
    print("="*60)
    
    for model in ['ESM-2', 'Dayhoff']:
        model_data = df[df['model'] == model]['perplexity']
        if len(model_data) > 0:
            mean_perp = model_data.mean()
            std_perp = model_data.std()
            print(f"{model:>8}: {mean_perp:.4f} Â± {std_perp:.4f} (n={len(model_data)})")
        else:
            print(f"{model:>8}: No data available")
    
    print("="*60)


def main():
    """Main function to run the perplexity scoring analysis."""
    parser = argparse.ArgumentParser(
        description="Compute perplexity scores for ESM-2 vs Dayhoff generated sequences"
    )
    parser.add_argument(
        "--esm2-fasta",
        default="/Users/melaku/Documents/Projects/EmbedDiff_ESM/data/decoded_embeddiff_esm2.fasta",
        help="Path to ESM-2 generated sequences FASTA file"
    )
    parser.add_argument(
        "--dayhoff-fasta",
        default="/Users/melaku/Documents/Projects/EmbedDiff_Dayhoff/data/decoded_embeddiff_dayhoff.fasta",
        help="Path to Dayhoff generated sequences FASTA file"
    )
    parser.add_argument(
        "--model",
        default="Rostlab/prot_t5_xl_uniref50",
        help="Protein language model to use for perplexity computation"
    )
    parser.add_argument(
        "--batch-size",
        type=int,
        default=16,
        help="Batch size for processing sequences (default: 16)"
    )
    
    args = parser.parse_args()
    
    # Check if input files exist
    if not os.path.exists(args.esm2_fasta):
        print(f"âŒ ESM-2 FASTA file not found: {args.esm2_fasta}")
        return
    
    if not os.path.exists(args.dayhoff_fasta):
        print(f"âŒ Dayhoff FASTA file not found: {args.dayhoff_fasta}")
        return
    
    # Create output directory
    os.makedirs("figures", exist_ok=True)
    
    try:
        # Compute perplexity scores
        print("ğŸš€ Starting perplexity scoring analysis...")
        results_df = compute_all_perplexities(args.esm2_fasta, args.dayhoff_fasta, args.model, args.batch_size)
        
        if len(results_df) == 0:
            print("âŒ No perplexity scores could be computed")
            return
        
        # Save results to CSV
        csv_path = "figures/perplexity_scores.csv"
        results_df.to_csv(csv_path, index=False)
        print(f"ğŸ’¾ Results saved to: {csv_path}")
        
        # Create publication-quality plot
        plot_path = "figures/perplexity_comparison.png"
        create_publication_plot(results_df, plot_path)
        
        # Print summary statistics
        print_summary_stats(results_df)
        
        print(f"\nğŸ‰ Perplexity scoring analysis completed successfully!")
        print(f"ğŸ“Š Results: {csv_path}")
        print(f"ğŸ“ˆ Plot: {plot_path}")
        
    except Exception as e:
        print(f"âŒ Error during analysis: {e}")
        raise


if __name__ == "__main__":
    main()
